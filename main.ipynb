{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import librosa\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from scipy.io import wavfile\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_path = \"D:\\\\Documents\\\\CMU_SUBJECTS\\\\BlackBoxAudioFx\\\\PedalNetRT\\\\data\\\\ts9_test1_in_FP32.wav\"\n",
    "out_path = \"D:\\\\Documents\\\\CMU_SUBJECTS\\\\BlackBoxAudioFx\\\\PedalNetRT\\\\data\\\\ts9_test1_out_FP32.wav\"  \n",
    "\n",
    "\n",
    "# Audio pre-processing and book keeping \n",
    "\n",
    "in_rate, in_data = wavfile.read(in_path)\n",
    "out_rate, out_data = wavfile.read(out_path)\n",
    "assert in_rate == out_rate, \"in_file and out_file must have same sample rate\"\n",
    "\n",
    "# Load audio files  \n",
    "def normalize(data):\n",
    "    data_max = max(data)\n",
    "    data_min = min(data)\n",
    "    data_norm = max(data_max,abs(data_min))\n",
    "    return data / data_norm\n",
    "\n",
    "# Trim the length of audio to equal the smaller wav file\n",
    "if len(in_data) > len(out_data):\n",
    "    print(\"Trimming input audio to match output audio\")\n",
    "in_data = in_data[0:len(out_data)]\n",
    "if len(out_data) > len(in_data): \n",
    "    print(\"Trimming output audio to match input audio\")\n",
    "out_data = out_data[0:len(in_data)]\n",
    "\n",
    "# If stereo data, use channel 0\n",
    "if len(in_data.shape) > 1:\n",
    "    print(\"[WARNING] Stereo data detected for in_data, only using first channel (left channel)\")\n",
    "    in_data = in_data[:,0]\n",
    "if len(out_data.shape) > 1:\n",
    "    print(\"[WARNING] Stereo data detected for out_data, only using first channel (left channel)\")\n",
    "    out_data = out_data[:,0]\n",
    "\n",
    "#normalize data\n",
    "if normalize == True:\n",
    "    in_data = normalize(in_data)\n",
    "    out_data = normalize(out_data)\n",
    "\n",
    "# Convert PCM16 to FP32\n",
    "if in_data.dtype == \"int16\":\n",
    "    in_data = in_data/32767\n",
    "    print(\"In data converted from PCM16 to FP32\")\n",
    "if out_data.dtype == \"int16\":\n",
    "    out_data = out_data/32767\n",
    "    print(\"Out data converted from PCM16 to FP32\")\n",
    "\n",
    "sample_time = 100e-3\n",
    "sample_size = int(in_rate * sample_time)\n",
    "length = len(in_data) - len(in_data) % sample_size\n",
    "\n",
    "x = in_data[:length].reshape((-1, 1, sample_size)).astype(np.float32)\n",
    "y = out_data[:length].reshape((-1, 1, sample_size)).astype(np.float32)\n",
    "\n",
    "split = lambda d: np.split(d, [int(len(d) * 0.6), int(len(d) * 0.8)])\n",
    "\n",
    "d = {}\n",
    "d[\"x_train\"], d[\"x_valid\"], d[\"x_test\"] = split(x)\n",
    "d[\"y_train\"], d[\"y_valid\"], d[\"y_test\"] = split(y)\n",
    "d[\"mean\"], d[\"std\"] = d[\"x_train\"].mean(), d[\"x_train\"].std()\n",
    "for key in \"x_train\", \"x_valid\", \"x_test\":\n",
    "    d[key] = (d[key] - d[\"mean\"]) / d[\"std\"] \n",
    "\n",
    "x_test, y_test = d[\"x_test\"], d[\"y_test\"]\n",
    "valid_data = TensorDataset(torch.from_numpy(d[\"x_valid\"]), torch.from_numpy(d[\"y_valid\"]))\n",
    "test_data  = TensorDataset(torch.from_numpy(d[\"x_test\"]), torch.from_numpy(d[\"y_test\"]))\n",
    "train_data = TensorDataset(torch.from_numpy(d[\"x_train\"]), torch.from_numpy(d[\"y_train\"]))\n",
    "\n",
    "\n",
    "num_workers, batch_size = 4, 64\n",
    "train_loader = DataLoader(train_data, batch_size = 64, num_workers= num_workers, shuffle= True)\n",
    "val_loader = DataLoader(valid_data, batch_size = 64, num_workers= num_workers)\n",
    "test_loader = DataLoader(test_data, batch_size = 64, num_workers= num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Error function of choice is the error to signal ratio \n",
    "\"\"\"\n",
    "def pre_emphasis_filter(x, coeff=0.95):\n",
    "   \n",
    "    \"\"\" \n",
    "    y[n] = x[n] - coeff * x[n-1] coefficient adapted from paper : 0.95\n",
    "    \"\"\" \n",
    "    return torch.cat((x[:, :, 0:1], x[:, :, 1:] - coeff * x[:, :, :-1]), dim=2)\n",
    "\n",
    "def error_to_signal(y, y_pred):\n",
    "    \"\"\"\n",
    "    Error to signal ratio with pre-emphasis filter:\n",
    "    https://www.mdpi.com/2076-3417/10/3/766/html\n",
    "    \n",
    "    \"\"\"\n",
    "    y, y_pred = pre_emphasis_filter(y), pre_emphasis_filter(y_pred)\n",
    "    return (y - y_pred).pow(2).sum(dim=2) / (y.pow(2).sum(dim=2) + 1e-10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dilated causal convolutions in WaveNet\n",
    "\n",
    "Causal convolutions \n",
    "Causal comes from causality, which means if we have a canonical 'direction' we are reading our data, then data that is ahead of the current position cannot factor \n",
    "into the calculation. This is most obvious in time series, so only previous timesteps factor into the current and not something 'future' relative to the current. \n",
    "But note it can also be applied to other forms of data like 2D images (like in PixelCNN for e.g.)\n",
    "\n",
    "The causal convolution concept comes about because when you do convolution, the kernel may overlap with the data from the 'future' points thus breaking causality. \n",
    "We don't want this so usually we introduce some kind of zero masking onto these points. This masking procedure is what sets apart causal convolution from standard \n",
    "convolution.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class CausalConv1d(torch.nn.Conv1d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n",
    "        self.__padding = (kernel_size - 1) * dilation\n",
    "\n",
    "        super(CausalConv1d, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=self.__padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        result = super(CausalConv1d, self).forward(input)\n",
    "        if self.__padding != 0:\n",
    "            return result[:, :, : -self.__padding]\n",
    "        return result\n",
    "\n",
    "\n",
    "def _conv_stack(dilations, in_channels, out_channels, kernel_size):\n",
    "    \"\"\"\n",
    "    Create stack of dilated convolutional layers, outlined in WaveNet paper:\n",
    "    https://arxiv.org/pdf/1609.03499.pdf\n",
    "    \"\"\"\n",
    "    return nn.ModuleList(\n",
    "        [\n",
    "            CausalConv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                dilation=d,\n",
    "                kernel_size=kernel_size,\n",
    "            )\n",
    "            for i, d in enumerate(dilations)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, num_channels, dilation_depth, num_repeat, kernel_size=2):\n",
    "        super(WaveNet, self).__init__()\n",
    "        dilations = [2 ** d for d in range(dilation_depth)] * num_repeat\n",
    "        internal_channels = int(num_channels * 2)\n",
    "        self.hidden = _conv_stack(dilations, num_channels, internal_channels, kernel_size)\n",
    "        self.residuals = _conv_stack(dilations, num_channels, num_channels, 1)\n",
    "        self.input_layer = CausalConv1d(\n",
    "            in_channels=1,\n",
    "            out_channels=num_channels,\n",
    "            kernel_size=1,\n",
    "        )\n",
    "\n",
    "        self.linear_mix = nn.Conv1d(\n",
    "            in_channels=num_channels * dilation_depth * num_repeat,\n",
    "            out_channels=1,\n",
    "            kernel_size=1,\n",
    "        )\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        skips = []\n",
    "        out = self.input_layer(out)\n",
    "\n",
    "        for hidden, residual in zip(self.hidden, self.residuals):\n",
    "            x = out\n",
    "            out_hidden = hidden(x)\n",
    "\n",
    "            # gated activation\n",
    "            # split (32,16,3) into two (16,16,3) for tanh and sigm calculations\n",
    "            out_hidden_split = torch.split(out_hidden, self.num_channels, dim=1)\n",
    "            out = torch.tanh(out_hidden_split[0]) * torch.sigmoid(out_hidden_split[1])\n",
    "\n",
    "            skips.append(out)\n",
    "\n",
    "            out = residual(out)\n",
    "            out = out + x[:, :, -out.size(2) :]\n",
    "\n",
    "        # modified \"postprocess\" step:\n",
    "        out = torch.cat([s[:, :, -out.size(2) :] for s in skips], dim=1)\n",
    "        out = self.linear_mix(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─ModuleList: 1-1                        --\n",
      "|    └─CausalConv1d: 2-1                 104\n",
      "|    └─CausalConv1d: 2-2                 104\n",
      "|    └─CausalConv1d: 2-3                 104\n",
      "|    └─CausalConv1d: 2-4                 104\n",
      "|    └─CausalConv1d: 2-5                 104\n",
      "|    └─CausalConv1d: 2-6                 104\n",
      "|    └─CausalConv1d: 2-7                 104\n",
      "|    └─CausalConv1d: 2-8                 104\n",
      "|    └─CausalConv1d: 2-9                 104\n",
      "|    └─CausalConv1d: 2-10                104\n",
      "|    └─CausalConv1d: 2-11                104\n",
      "|    └─CausalConv1d: 2-12                104\n",
      "|    └─CausalConv1d: 2-13                104\n",
      "|    └─CausalConv1d: 2-14                104\n",
      "|    └─CausalConv1d: 2-15                104\n",
      "|    └─CausalConv1d: 2-16                104\n",
      "|    └─CausalConv1d: 2-17                104\n",
      "|    └─CausalConv1d: 2-18                104\n",
      "├─ModuleList: 1-2                        --\n",
      "|    └─CausalConv1d: 2-19                20\n",
      "|    └─CausalConv1d: 2-20                20\n",
      "|    └─CausalConv1d: 2-21                20\n",
      "|    └─CausalConv1d: 2-22                20\n",
      "|    └─CausalConv1d: 2-23                20\n",
      "|    └─CausalConv1d: 2-24                20\n",
      "|    └─CausalConv1d: 2-25                20\n",
      "|    └─CausalConv1d: 2-26                20\n",
      "|    └─CausalConv1d: 2-27                20\n",
      "|    └─CausalConv1d: 2-28                20\n",
      "|    └─CausalConv1d: 2-29                20\n",
      "|    └─CausalConv1d: 2-30                20\n",
      "|    └─CausalConv1d: 2-31                20\n",
      "|    └─CausalConv1d: 2-32                20\n",
      "|    └─CausalConv1d: 2-33                20\n",
      "|    └─CausalConv1d: 2-34                20\n",
      "|    └─CausalConv1d: 2-35                20\n",
      "|    └─CausalConv1d: 2-36                20\n",
      "├─CausalConv1d: 1-3                      8\n",
      "├─Conv1d: 1-4                            73\n",
      "=================================================================\n",
      "Total params: 2,313\n",
      "Trainable params: 2,313\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "hyperparameters \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "num_channels = 4\n",
    "dilation_depth = 9\n",
    "num_repeat = 2 \n",
    "kernel_size =3\n",
    "learning_rate, batch_size = 3e-3, 64\n",
    "wavenet_model = WaveNet(\n",
    "            num_channels,\n",
    "            dilation_depth,\n",
    "            num_repeat,\n",
    "            kernel_size\n",
    "        )\n",
    "summary(wavenet_model) \n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device == \"cuda\"\n",
    "    wavenet_model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(wavenet_model.parameters(), lr= learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple class for early stopping \n",
    "[stack overflow : https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch]\n",
    "\"\"\"\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "stopEARLY = EarlyStopper(patience= 20, min_delta = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop with a custom divergence function error to signal ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0/1000] ---- Train Loss: 0.8094963431358337, Valid Loss: 0.8480744361877441 \n",
      "Epoch: [1/1000] ---- Train Loss: 0.6749414801597595, Valid Loss: 0.5772479176521301 \n",
      "Epoch: [2/1000] ---- Train Loss: 0.6664125323295593, Valid Loss: 0.5072468519210815 \n",
      "Epoch: [3/1000] ---- Train Loss: 0.5741808414459229, Valid Loss: 0.43390342593193054 \n",
      "Epoch: [4/1000] ---- Train Loss: 0.5099707841873169, Valid Loss: 0.4239423871040344 \n",
      "Epoch: [5/1000] ---- Train Loss: 0.5278087854385376, Valid Loss: 0.401146799325943 \n",
      "Epoch: [6/1000] ---- Train Loss: 0.3982592821121216, Valid Loss: 0.36667245626449585 \n",
      "Epoch: [7/1000] ---- Train Loss: 0.33165380358695984, Valid Loss: 0.3450269401073456 \n",
      "Epoch: [8/1000] ---- Train Loss: 0.24998284876346588, Valid Loss: 0.33827003836631775 \n",
      "Epoch: [9/1000] ---- Train Loss: 0.2462148219347, Valid Loss: 0.3360155522823334 \n",
      "Epoch: [10/1000] ---- Train Loss: 0.25515618920326233, Valid Loss: 0.3237763047218323 \n",
      "Epoch: [11/1000] ---- Train Loss: 0.2669546604156494, Valid Loss: 0.3149687349796295 \n",
      "Epoch: [12/1000] ---- Train Loss: 0.23062525689601898, Valid Loss: 0.3096006512641907 \n",
      "Epoch: [13/1000] ---- Train Loss: 0.20332227647304535, Valid Loss: 0.2890239953994751 \n",
      "Epoch: [14/1000] ---- Train Loss: 0.2382788360118866, Valid Loss: 0.26441770792007446 \n",
      "Epoch: [15/1000] ---- Train Loss: 0.1697693020105362, Valid Loss: 0.25755640864372253 \n",
      "Epoch: [16/1000] ---- Train Loss: 0.21444310247898102, Valid Loss: 0.23313945531845093 \n",
      "Epoch: [17/1000] ---- Train Loss: 0.15505315363407135, Valid Loss: 0.21207992732524872 \n",
      "Epoch: [18/1000] ---- Train Loss: 0.14631019532680511, Valid Loss: 0.19218187034130096 \n",
      "Epoch: [19/1000] ---- Train Loss: 0.13416562974452972, Valid Loss: 0.17838610708713531 \n",
      "Epoch: [20/1000] ---- Train Loss: 0.17912501096725464, Valid Loss: 0.17155496776103973 \n",
      "Epoch: [21/1000] ---- Train Loss: 0.1440524458885193, Valid Loss: 0.1617286056280136 \n",
      "Epoch: [22/1000] ---- Train Loss: 0.18761903047561646, Valid Loss: 0.14648349583148956 \n",
      "Epoch: [23/1000] ---- Train Loss: 0.09630925953388214, Valid Loss: 0.13556018471717834 \n",
      "Epoch: [24/1000] ---- Train Loss: 0.09943841397762299, Valid Loss: 0.13092143833637238 \n",
      "Epoch: [25/1000] ---- Train Loss: 0.12288641184568405, Valid Loss: 0.12281171977519989 \n",
      "Epoch: [26/1000] ---- Train Loss: 0.07049859315156937, Valid Loss: 0.13326480984687805 \n",
      "Epoch: [27/1000] ---- Train Loss: 0.08566185086965561, Valid Loss: 0.11179721355438232 \n",
      "Epoch: [28/1000] ---- Train Loss: 0.08342786133289337, Valid Loss: 0.09397392719984055 \n",
      "Epoch: [29/1000] ---- Train Loss: 0.07152461260557175, Valid Loss: 0.09641747921705246 \n",
      "Epoch: [30/1000] ---- Train Loss: 0.06783877313137054, Valid Loss: 0.08746405690908432 \n",
      "Epoch: [31/1000] ---- Train Loss: 0.11573585867881775, Valid Loss: 0.08753650635480881 \n",
      "Epoch: [32/1000] ---- Train Loss: 0.13384145498275757, Valid Loss: 0.08498088270425797 \n",
      "Epoch: [33/1000] ---- Train Loss: 0.053601399064064026, Valid Loss: 0.07815499603748322 \n",
      "Epoch: [34/1000] ---- Train Loss: 0.0502685122191906, Valid Loss: 0.07580476999282837 \n",
      "Epoch: [35/1000] ---- Train Loss: 0.06434962153434753, Valid Loss: 0.06810390949249268 \n",
      "Epoch: [36/1000] ---- Train Loss: 0.1018688902258873, Valid Loss: 0.07592816650867462 \n",
      "Epoch: [37/1000] ---- Train Loss: 0.1198083758354187, Valid Loss: 0.0645413026213646 \n",
      "Epoch: [38/1000] ---- Train Loss: 0.0863972082734108, Valid Loss: 0.05997733026742935 \n",
      "Epoch: [39/1000] ---- Train Loss: 0.06151708960533142, Valid Loss: 0.07455521076917648 \n",
      "Epoch: [40/1000] ---- Train Loss: 0.08741379529237747, Valid Loss: 0.055006761103868484 \n",
      "Epoch: [41/1000] ---- Train Loss: 0.05352253466844559, Valid Loss: 0.054491229355335236 \n",
      "Epoch: [42/1000] ---- Train Loss: 0.07649524509906769, Valid Loss: 0.05404912680387497 \n",
      "Epoch: [43/1000] ---- Train Loss: 0.04703180491924286, Valid Loss: 0.051090557128190994 \n",
      "Epoch: [44/1000] ---- Train Loss: 0.10579682141542435, Valid Loss: 0.04873252287507057 \n",
      "Epoch: [45/1000] ---- Train Loss: 0.060013297945261, Valid Loss: 0.048679765313863754 \n",
      "Epoch: [46/1000] ---- Train Loss: 0.04452519863843918, Valid Loss: 0.04954756423830986 \n",
      "Epoch: [47/1000] ---- Train Loss: 0.05467510595917702, Valid Loss: 0.06133774667978287 \n",
      "Epoch: [48/1000] ---- Train Loss: 0.04131360352039337, Valid Loss: 0.0471520870923996 \n",
      "Epoch: [49/1000] ---- Train Loss: 0.06386436522006989, Valid Loss: 0.04541925713419914 \n",
      "Epoch: [50/1000] ---- Train Loss: 0.08154277503490448, Valid Loss: 0.044382959604263306 \n",
      "Epoch: [51/1000] ---- Train Loss: 0.1128549873828888, Valid Loss: 0.06332049518823624 \n",
      "Epoch: [52/1000] ---- Train Loss: 0.1319713592529297, Valid Loss: 0.04898235946893692 \n",
      "Epoch: [53/1000] ---- Train Loss: 0.05756382271647453, Valid Loss: 0.043140947818756104 \n",
      "Epoch: [54/1000] ---- Train Loss: 0.07162027806043625, Valid Loss: 0.04904547333717346 \n",
      "Epoch: [55/1000] ---- Train Loss: 0.09416233748197556, Valid Loss: 0.03910297900438309 \n",
      "Epoch: [56/1000] ---- Train Loss: 0.09188809990882874, Valid Loss: 0.041860368102788925 \n",
      "Epoch: [57/1000] ---- Train Loss: 0.03811974823474884, Valid Loss: 0.03816875070333481 \n",
      "Epoch: [58/1000] ---- Train Loss: 0.038561686873435974, Valid Loss: 0.040150389075279236 \n",
      "Epoch: [59/1000] ---- Train Loss: 0.07642045617103577, Valid Loss: 0.03636423870921135 \n",
      "Epoch: [60/1000] ---- Train Loss: 0.037576448172330856, Valid Loss: 0.03619514778256416 \n",
      "Epoch: [61/1000] ---- Train Loss: 0.046196967363357544, Valid Loss: 0.043394412845373154 \n",
      "Epoch: [62/1000] ---- Train Loss: 0.039456795901060104, Valid Loss: 0.037193603813648224 \n",
      "Epoch: [63/1000] ---- Train Loss: 0.07780114561319351, Valid Loss: 0.03585544228553772 \n",
      "Epoch: [64/1000] ---- Train Loss: 0.07390148192644119, Valid Loss: 0.052908699959516525 \n",
      "Epoch: [65/1000] ---- Train Loss: 0.0841224268078804, Valid Loss: 0.035569097846746445 \n",
      "Epoch: [66/1000] ---- Train Loss: 0.0959559828042984, Valid Loss: 0.03381715342402458 \n",
      "Epoch: [67/1000] ---- Train Loss: 0.06204359978437424, Valid Loss: 0.03787309303879738 \n",
      "Epoch: [68/1000] ---- Train Loss: 0.08230018615722656, Valid Loss: 0.03568631410598755 \n",
      "Epoch: [69/1000] ---- Train Loss: 0.06159471347928047, Valid Loss: 0.032532818615436554 \n",
      "Epoch: [70/1000] ---- Train Loss: 0.05122784897685051, Valid Loss: 0.03200541436672211 \n",
      "Epoch: [71/1000] ---- Train Loss: 0.04440998286008835, Valid Loss: 0.03298347443342209 \n",
      "Epoch: [72/1000] ---- Train Loss: 0.059112440794706345, Valid Loss: 0.029039528220891953 \n",
      "Epoch: [73/1000] ---- Train Loss: 0.03561389818787575, Valid Loss: 0.028203977271914482 \n",
      "Epoch: [74/1000] ---- Train Loss: 0.037818849086761475, Valid Loss: 0.027994342148303986 \n",
      "Epoch: [75/1000] ---- Train Loss: 0.03727118298411369, Valid Loss: 0.029791438952088356 \n",
      "Epoch: [76/1000] ---- Train Loss: 0.028680430725216866, Valid Loss: 0.03810355067253113 \n",
      "Epoch: [77/1000] ---- Train Loss: 0.026460612192749977, Valid Loss: 0.026100894436240196 \n",
      "Epoch: [78/1000] ---- Train Loss: 0.08473104238510132, Valid Loss: 0.03171771764755249 \n",
      "Epoch: [79/1000] ---- Train Loss: 0.030399423092603683, Valid Loss: 0.03689210116863251 \n",
      "Epoch: [80/1000] ---- Train Loss: 0.05169302970170975, Valid Loss: 0.030205557122826576 \n",
      "Epoch: [81/1000] ---- Train Loss: 0.056608639657497406, Valid Loss: 0.027589544653892517 \n",
      "Epoch: [82/1000] ---- Train Loss: 0.034262798726558685, Valid Loss: 0.028485948219895363 \n",
      "Epoch: [83/1000] ---- Train Loss: 0.05350011959671974, Valid Loss: 0.025481821969151497 \n",
      "Epoch: [84/1000] ---- Train Loss: 0.03329646587371826, Valid Loss: 0.026941372081637383 \n",
      "Epoch: [85/1000] ---- Train Loss: 0.02240917459130287, Valid Loss: 0.029933486133813858 \n",
      "Epoch: [86/1000] ---- Train Loss: 0.08063838630914688, Valid Loss: 0.031900614500045776 \n",
      "Epoch: [87/1000] ---- Train Loss: 0.06669923663139343, Valid Loss: 0.032341282814741135 \n",
      "Epoch: [88/1000] ---- Train Loss: 0.09020970016717911, Valid Loss: 0.027439497411251068 \n",
      "Epoch: [89/1000] ---- Train Loss: 0.036700986325740814, Valid Loss: 0.02647746540606022 \n",
      "Epoch: [90/1000] ---- Train Loss: 0.06326345354318619, Valid Loss: 0.02538684383034706 \n",
      "Epoch: [91/1000] ---- Train Loss: 0.08808115869760513, Valid Loss: 0.028150787577033043 \n",
      "Epoch: [92/1000] ---- Train Loss: 0.05120536684989929, Valid Loss: 0.024483559653162956 \n",
      "Epoch: [93/1000] ---- Train Loss: 0.03431113809347153, Valid Loss: 0.024033159017562866 \n",
      "Epoch: [94/1000] ---- Train Loss: 0.08577815443277359, Valid Loss: 0.02662740647792816 \n",
      "Epoch: [95/1000] ---- Train Loss: 0.027248971164226532, Valid Loss: 0.034133180975914 \n",
      "Epoch: [96/1000] ---- Train Loss: 0.029503801837563515, Valid Loss: 0.02568506821990013 \n",
      "Epoch: [97/1000] ---- Train Loss: 0.03722267970442772, Valid Loss: 0.029645269736647606 \n",
      "Epoch: [98/1000] ---- Train Loss: 0.026681149378418922, Valid Loss: 0.02338767796754837 \n",
      "Epoch: [99/1000] ---- Train Loss: 0.07756048440933228, Valid Loss: 0.048039522022008896 \n",
      "Epoch: [100/1000] ---- Train Loss: 0.02789381518959999, Valid Loss: 0.026745399460196495 \n",
      "Epoch: [101/1000] ---- Train Loss: 0.03643057495355606, Valid Loss: 0.023137373849749565 \n",
      "Epoch: [102/1000] ---- Train Loss: 0.030669856816530228, Valid Loss: 0.02454754151403904 \n",
      "Epoch: [103/1000] ---- Train Loss: 0.024371791630983353, Valid Loss: 0.021869905292987823 \n",
      "Epoch: [104/1000] ---- Train Loss: 0.032431334257125854, Valid Loss: 0.022132370620965958 \n",
      "Epoch: [105/1000] ---- Train Loss: 0.11238651722669601, Valid Loss: 0.033521801233291626 \n",
      "Epoch: [106/1000] ---- Train Loss: 0.02425950951874256, Valid Loss: 0.03330349922180176 \n",
      "Epoch: [107/1000] ---- Train Loss: 0.05203673243522644, Valid Loss: 0.025535672903060913 \n",
      "Epoch: [108/1000] ---- Train Loss: 0.07992798089981079, Valid Loss: 0.038182977586984634 \n",
      "Epoch: [109/1000] ---- Train Loss: 0.026516325771808624, Valid Loss: 0.02495984360575676 \n",
      "Epoch: [110/1000] ---- Train Loss: 0.030435800552368164, Valid Loss: 0.025409521535038948 \n",
      "Epoch: [111/1000] ---- Train Loss: 0.04723627120256424, Valid Loss: 0.02830367349088192 \n",
      "Epoch: [112/1000] ---- Train Loss: 0.03721732273697853, Valid Loss: 0.022503357380628586 \n",
      "Epoch: [113/1000] ---- Train Loss: 0.025842824950814247, Valid Loss: 0.022998668253421783 \n",
      "Epoch: [114/1000] ---- Train Loss: 0.03722132369875908, Valid Loss: 0.02940855361521244 \n",
      "Epoch: [115/1000] ---- Train Loss: 0.053633540868759155, Valid Loss: 0.02586069330573082 \n",
      "Epoch: [116/1000] ---- Train Loss: 0.05729597806930542, Valid Loss: 0.05396793410181999 \n",
      "Epoch: [117/1000] ---- Train Loss: 0.05777828395366669, Valid Loss: 0.034724511206150055 \n",
      "Epoch: [118/1000] ---- Train Loss: 0.036733463406562805, Valid Loss: 0.04731419309973717 \n",
      "Epoch: [119/1000] ---- Train Loss: 0.08470979332923889, Valid Loss: 0.03083837777376175 \n",
      "Epoch: [120/1000] ---- Train Loss: 0.03635275736451149, Valid Loss: 0.022298475727438927 \n",
      "Epoch: [121/1000] ---- Train Loss: 0.03924211114645004, Valid Loss: 0.027848461642861366 \n",
      "Epoch: [122/1000] ---- Train Loss: 0.02289784513413906, Valid Loss: 0.030277447775006294 \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train loop with early stopping \n",
    "\"\"\"\n",
    "EPOCHS = 1000\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    wavenet_model.train()\n",
    "    for batch, (train_in, train_out) in enumerate(train_loader): \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_in, train_out = train_in.to(device), train_out.to(device)\n",
    "        out = wavenet_model(train_in)\n",
    "        train_loss = error_to_signal(out[:,:,-out.size(2):], train_out).mean()\n",
    "        train_loss.backward()\n",
    "        train_loss = train_loss.detach().numpy()\n",
    "        optimizer.step()\n",
    "\n",
    "        del train_in\n",
    "\n",
    "    wavenet_model.eval()\n",
    "\n",
    "    for batch, (valid_in, valid_out) in enumerate(val_loader): \n",
    "        valid_in, valid_out = valid_in.to(device), valid_out.to(device)\n",
    "        out = wavenet_model(valid_in)\n",
    "        valid_loss = error_to_signal(out[:,:,-out.size(2):], valid_out).mean()\n",
    "        valid_loss = valid_loss.detach().numpy()\n",
    "        del valid_in\n",
    "    \n",
    "    if stopEARLY.early_stop(validation_loss= valid_loss):\n",
    "        break \n",
    "\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': wavenet_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,'valid_loss': valid_loss,\n",
    "            }, \"D:\\\\Documents\\\\CMU_SUBJECTS\\\\BlackBoxAudioFx\\\\NeuralAudioModelling\\\\ckpt\\\\epoch_{}.pt\".format(epoch))\n",
    "    print(\"Epoch: [{}/{}] ---- Train Loss: {}, Valid Loss: {} \".format(epoch, EPOCHS, train_loss, valid_loss))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing the model \n",
    "\n",
    "def save(name, data): \n",
    "    wavfile.write(name, 44100, data.flatten().astype(np.float32))\n",
    "\n",
    "load_ckpt = torch.load(\"D:\\\\Documents\\\\CMU_SUBJECTS\\\\BlackBoxAudioFx\\\\NeuralAudioModelling\\\\ckpt\\\\epoch_112.pt\")\n",
    "wavenet_model.load_state_dict(load_ckpt['model_state_dict'])\n",
    "wavenet_model.eval()\n",
    "\n",
    "prev_sample = np.concatenate((np.zeros_like(x_test[0:1]), x_test[:-1]), axis=0)\n",
    "pad_x_test = np.concatenate((prev_sample, x_test), axis=2)\n",
    "\n",
    "y_pred = []\n",
    "for x in np.array_split(pad_x_test, 10):\n",
    "    y_pred.append(wavenet_model(torch.from_numpy(x)).detach().numpy())\n",
    "\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_pred = y_pred[:, :, -x_test.shape[2] :]\n",
    "save_path = \"D:\\\\Documents\\\\CMU_SUBJECTS\\\\BlackBoxAudioFx\\\\NeuralAudioModelling\\\\\"\n",
    "save(save_path + \"y_pred.wav\", y_pred)\n",
    "save(save_path + \"x_test.wav\", d[\"x_test\"] * d[\"std\"] + d[\"mean\"])\n",
    "save(save_path + \"y_test.wav\", d[\"y_test\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PointNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be71f7ebca6fc406e8f2b7eb97fc71d65ed284e191505e45141d8f3008802363"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
